# TensorRT æ€§èƒ½ç“¶é¢ˆåˆ†æä¸ä¼˜åŒ–æŒ‡å—

## ğŸ“Š ç›®å½•
1. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
2. [åˆ†ææ–¹æ³•](#åˆ†ææ–¹æ³•)
3. [ä¼˜åŒ–ç­–ç•¥](#ä¼˜åŒ–ç­–ç•¥)
4. [å®è·µä¾‹å­](#å®è·µä¾‹å­)

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### Step 1: ç¼–è¯‘ Profiling å·¥å…·

```bash
cd /home/zzwtx/fl/edge/build
cmake ..
make tensorrt_profiling
```

### Step 2: è¿è¡Œåˆ†æ

```bash
./tensorrt_profiling ../mobilenetv2_fp16.engine
```

### è¾“å‡ºç¤ºä¾‹
```
================================================================================
              TensorRT Layer Profiling Results
================================================================================
Layer Name                              Type                Time (ms)   % of Total
--------------------------------------------------------------------------------
conv1                                   Convolution         2.1234      15.50%
bn1                                     Scale               0.3456       2.51%
relu1                                   Activation         0.2345       1.71%
layer1/block0/conv                      Convolution         1.8901      13.76%
layer1/block1/conv                      Convolution         1.7654      12.85%
...
total_time_sum                          (all layers)       13.7654     100.00%
--------------------------------------------------------------------------------
Total GPU Execution Time: 13.7654 ms

ğŸ”¥ Top 5 Time-Consuming Layers (Optimization Candidates):
  1. [18.45%] conv1 (Convolution) - 2.5345 ms
  2. [12.34%] layer2/conv (Convolution) - 1.6923 ms
  3. [11.23%] layer3/conv (Convolution) - 1.5432 ms
  4. [9.87%] layer4/conv (Convolution) - 1.3567 ms
  5. [7.65%] fc1 (FullyConnected) - 1.0523 ms

================================================================================
```

---

## ğŸ” åˆ†ææ–¹æ³•

### æ–¹æ³•1: TensorRT å†…ç½® Profilerï¼ˆæ¨è - æœ€ç®€å•ï¼‰

**ä¼˜ç‚¹**ï¼š
- âœ… æ— éœ€é¢å¤–å·¥å…·ï¼Œä»£ç é›†æˆ
- âœ… é€å±‚æ—¶é—´ç»Ÿè®¡
- âœ… è‡ªåŠ¨åˆ†ç±» Top 5 ç“¶é¢ˆ

**å±€é™æ€§**ï¼š
- âŒ ä¸æ˜¾ç¤º GPU åˆ©ç”¨ç‡
- âŒ ä¸æ˜¾ç¤ºå†…å­˜å¸¦å®½å ç”¨
- âŒ ä¸æ˜¾ç¤ºç¼“å­˜æ•ˆç‡

**æœ€ä½³ç”¨é€”**ï¼šå¿«é€Ÿæ‰¾å‡ºæ—¶é—´æ¶ˆè€—æœ€å¤šçš„å±‚

---

### æ–¹æ³•2: NVIDIA Nsysï¼ˆæ·±åº¦æ€§èƒ½åˆ†æï¼‰

**å®‰è£… Nsys**
```bash
# é€šå¸¸éš CUDA Toolkit ä¸€èµ·å®‰è£…
which nsys

# å¦‚æœæ²¡æœ‰ï¼Œå¯ä»¥å•ç‹¬ä¸‹è½½
# https://developer.nvidia.com/nsys/nvidia-systems-profiler
```

**ä½¿ç”¨æ–¹æ³•**
```bash
# 1. è¿è¡Œå¸¦ profiling çš„ç¨‹åº
nsys profile -o profile_report ./tensorrt_profiling ../mobilenetv2_fp16.engine

# 2. ç”ŸæˆæŠ¥å‘Š
# è¾“å‡ºæ–‡ä»¶ï¼šprofile_report.nsys-rep

# 3. åœ¨ VS Code ä¸­æ‰“å¼€æˆ–ä½¿ç”¨ nsys-ui æŸ¥çœ‹
nsys-ui profile_report.nsys-rep
```

**è¾“å‡ºå†…å®¹**ï¼š
- GPU æ—¶é—´è½´å›¾è¡¨
- æ ¸å‡½æ•°æ‰§è¡Œæ—¶é—´
- GPU å†…å­˜ä¼ è¾“
- CPU-GPU åŒæ­¥ç‚¹
- å ç”¨ç‡å’Œæ•ˆç‡æŒ‡æ ‡

---

### æ–¹æ³•3: NVIDIA NCUï¼ˆå¾®æ¶æ„çº§åˆ†æï¼‰

**æœ€è¯¦ç»†çš„æ€§èƒ½åˆ†æ**ï¼ˆä½†æ‰§è¡Œæ—¶é—´é•¿ï¼‰

```bash
# è¿è¡Œ NCU profiler
ncu -o profile_ncu ./tensorrt_profiling ../mobilenetv2_fp16.engine

# æŸ¥çœ‹ç»“æœ
ncu --import profile_ncu.ncu-rep
```

**æä¾›çš„æŒ‡æ ‡**ï¼š
- SM (Streaming Multiprocessor) åˆ©ç”¨ç‡
- å†…å­˜å¸¦å®½
- ç¼“å­˜å‘½ä¸­ç‡
- æŒ‡ä»¤ååé‡
- åˆ†æ”¯é¢„æµ‹æ•ˆç‡

---

## ğŸ“ˆ åˆ†æç»“æœè§£è¯»

### æ—¶é—´æ¶ˆè€—åˆ†å¸ƒå…¸å‹æ¨¡å¼

#### **æ¨¡å¼ 1: å·ç§¯ä¸»å¯¼ï¼ˆMobileNetV2 å…¸å‹ï¼‰**
```
Convolution: 85% â† ä¼˜åŒ–é‡ç‚¹
Activation:  8%
Pooling:     4%
FullyConnected: 3%
```
â†’ **ä¼˜åŒ–ç­–ç•¥**ï¼šç®—å­èåˆï¼ˆConv+BN+Activationï¼‰ã€Kernelä¼˜åŒ–

#### **æ¨¡å¼ 2: å†…å­˜å—é™**
```
H2D Memory Copy: 30%
Inference:       50%
D2H Memory Copy: 20%
```
â†’ **ä¼˜åŒ–ç­–ç•¥**ï¼šå‡å°‘æ•°æ®ä¼ è¾“ã€ä½¿ç”¨å¼‚æ­¥ä¼ è¾“ã€pinned memory

#### **æ¨¡å¼ 3: ç®—å­å¤šæ ·åŒ–**
```
Conv: 30%, FC: 25%, Gather: 20%, Reshape: 15%, Others: 10%
```
â†’ **ä¼˜åŒ–ç­–ç•¥**ï¼šé’ˆå¯¹æ€§ä¼˜åŒ–å¤šä¸ªç®—å­

---

## ğŸ› ï¸ ä¼˜åŒ–ç­–ç•¥

### ä¼˜åŒ–å±‚çº§ 1: ç®—å­èåˆï¼ˆOperator Fusionï¼‰

**ä»€ä¹ˆæ˜¯ç®—å­èåˆ**ï¼š
å°†å¤šä¸ªç›¸é‚»çš„å°ç®—å­åˆå¹¶æˆä¸€ä¸ªå¤§ç®—å­ï¼Œå‡å°‘å†…å­˜å¾€è¿”ã€‚

**å…¸å‹èåˆæ–¹æ¡ˆ**ï¼š

```
åŸå§‹å›¾ï¼š
Input â†’ Conv â†’ BatchNorm â†’ ReLU â†’ Output
                  â†“           â†“
                 åˆ†åˆ«è°ƒç”¨3ä¸ªKernel

èåˆåï¼š
Input â†’ Conv+BatchNorm+ReLU â†’ Output
              â†“
            ä¸€ä¸ªKernelï¼Œå‡å°‘å†…å­˜è®¿é—®
```

**MobileNetV2 å¸¸è§èåˆ**ï¼š
1. **Conv + BatchNorm**
   - å‡å°‘ ~30% æ—¶é—´
   - TensorRT é€šå¸¸è‡ªåŠ¨åšè¿™ä¸ª

2. **Conv + Activation** (ReLU/Hardswish)
   - å‡å°‘ ~20% æ—¶é—´
   - é€šè¿‡ `ITensor::kISH_ACTIVATION` å®ç°

3. **Depthwise Conv + Pointwise Conv**
   - å‡å°‘ ~15% æ—¶é—´

**å¦‚ä½•åœ¨ TensorRT ä¸­å¯ç”¨**ï¼š

```cpp
// åœ¨ builder ä¸­è®¾ç½®èåˆé€‰é¡¹
config->setFlag(BuilderFlag::kFP16);  // å¯ç”¨ FP16ï¼Œä¿ƒè¿›èåˆ
config->setFlag(BuilderFlag::kINT8);  // INT8 ä¹Ÿä¼šè§¦å‘èåˆ

// æ£€æŸ¥èåˆæƒ…å†µ
for (int i = 0; i < engine->getNbLayers(); ++i) {
    ILayer* layer = engine->getLayer(i);
    std::cout << "Layer " << i << ": " << layer->getName() 
              << " - Type: " << (int)layer->getType() << std::endl;
}
```

---

### ä¼˜åŒ–å±‚çº§ 2: è‡ªå®šä¹‰ Kernel å®ç°

**ä»€ä¹ˆæ—¶å€™éœ€è¦**ï¼š
- TensorRT çš„èåˆè¿˜ä¸å¤Ÿ
- ç‰¹å®šçš„ç®—å­ç»„åˆæ²¡æœ‰å¯¹åº”çš„ä¼˜åŒ– kernel
- éœ€è¦è¶…å‡ºé¢„æœŸçš„æ€§èƒ½

**å®ç°æ­¥éª¤**ï¼š

#### Step 1: è¯†åˆ«å…³é”®ç®—å­
ä» profiling ç»“æœä¸­æ‰¾å‡ºï¼š
```
Top 1: depthwise_conv_layer - 3.2 ms (22%)  â† è¿™ä¸ª
Top 2: pointwise_conv_layer - 2.8 ms (19%)
```

#### Step 2: ç¼–å†™è‡ªå®šä¹‰ CUDA Kernel

```cuda
// custom_kernel.cu
// èåˆ Depthwise Conv + BatchNorm + ReLU

__global__ void depthwise_conv_bn_relu_kernel(
    const float* input,           // (N, C, H, W)
    const float* weight,          // (C, 1, K, K) for depthwise
    const float* bn_scale,        // (C,)
    const float* bn_bias,         // (C,)
    float* output,                // (N, C, H', W')
    int N, int C, int H, int W, int K, int stride, int padding
) {
    // çº¿ç¨‹æ˜ å°„åˆ°è¾“å‡ºä½ç½®
    int out_idx = blockIdx.x * blockDim.x + threadIdx.x;
    
    // è®¡ç®—å·ç§¯
    // åº”ç”¨æ‰¹å½’ä¸€åŒ–
    // åº”ç”¨ ReLU
    // å†™å›è¾“å‡º
}
```

#### Step 3: åŒ…è£…ä¸º TensorRT Plugin

```cpp
// custom_plugin.cpp
class DepthwiseConvBnReLU : public nvinfer1::IPluginV2DynamicExt {
public:
    nvinfer1::IPluginV2DynamicExt* clone() const noexcept override { /* ... */ }
    
    nvinfer1::DimsExprs getOutputDimensions(
        int outputIndex,
        const nvinfer1::DimsExprs* inputs,
        int nbInputs,
        nvinfer1::IExprBuilder& exprBuilder) noexcept override { /* ... */ }
    
    void configurePlugin(
        const nvinfer1::DynamicPluginTensorDesc* in,
        int nbInputs,
        const nvinfer1::DynamicPluginTensorDesc* out,
        int nbOutputs) noexcept override { /* ... */ }
    
    int enqueue(const nvinfer1::PluginTensorDesc* inputDesc,
                const nvinfer1::PluginTensorDesc* outputDesc,
                const void* const* inputs,
                void* const* outputs,
                void* workspace,
                cudaStream_t stream) noexcept override {
        // è°ƒç”¨ custom_kernel
        depthwise_conv_bn_relu_kernel<<<blocks, threads, 0, stream>>>(
            (const float*)inputs[0],
            (const float*)inputs[1],
            // ... å…¶ä»–å‚æ•°
        );
        return 0;
    }
};
```

---

### ä¼˜åŒ–å±‚çº§ 3: é‡åŒ– (Quantization)

å¦‚æœä¸»è¦ç“¶é¢ˆä¸æ˜¯æ—¶é—´è€Œæ˜¯åŠŸè€—/å†…å­˜ï¼š

```cpp
// INT8 é‡åŒ–ï¼ˆé€šå¸¸å¿« 3-4 å€ï¼‰
config->setFlag(BuilderFlag::kINT8);
config->setInt8Calibrator(calibrator);

// FP16ï¼ˆé€šå¸¸å¿« 1.5-2 å€ï¼‰
config->setFlag(BuilderFlag::kFP16);
```

---

## ğŸ“‹ å®è·µä¾‹å­

### åœºæ™¯ï¼šMobileNetV2 ä¼˜åŒ–

**Step 1: Profile åŸºçº¿**
```bash
./tensorrt_profiling ../mobilenetv2_fp32.engine
```

å¯èƒ½è¾“å‡ºï¼š
```
Top Time Consumers:
  1. [18%] conv1_0 (Convolution) - 2.5 ms
  2. [12%] layer2_0_conv (Convolution) - 1.8 ms
  3. [10%] layer3_0_conv (Convolution) - 1.5 ms
  4. [8%] layer4_0_conv (Convolution) - 1.2 ms
  5. [7%] fc (FullyConnected) - 1.0 ms
Total: 14.5 ms â†’ ~69 FPS
```

**Step 2: å¯ç”¨ TensorRT èåˆ**
```python
# åœ¨ tensorRT_example.py ä¸­
config.set_flag(trt.BuilderFlag.FP16)  # å¯ç”¨FP16ï¼Œä¿ƒè¿›èåˆ

# é‡æ–°æ„å»ºå¼•æ“
engine = builder.build_engine(network, config)
```

æ–°ç»“æœï¼š
```
Total: 9.2 ms â†’ ~109 FPS
æ”¹å–„: (14.5 - 9.2) / 14.5 = 36% âœ…
```

**Step 3: å†™å…¥è‡ªå®šä¹‰ Depthwise Conv èåˆ Kernel**
ï¼ˆå¦‚æœä¸Šè¿°è¿˜ä¸å¤Ÿï¼‰

æ–°ç»“æœï¼š
```
Total: 7.1 ms â†’ ~141 FPS
ç´¯ç§¯æ”¹å–„: (14.5 - 7.1) / 14.5 = 51% âœ…
```

---

## ğŸ¯ ä¼˜åŒ–å†³ç­–æ ‘

```
è§‚å¯Ÿåˆ°æ€§èƒ½ç“¶é¢ˆ
    â†“
é—®é¢˜æ˜¯ä»€ä¹ˆç±»å‹ï¼Ÿ
    â”œâ”€ å·ç§¯å±‚æ…¢ â†’ Conv + BN + Activation èåˆ
    â”‚            â†’ è‡ªå®šä¹‰ Kernelï¼ˆDepthwiseï¼‰
    â”‚            â†’ INT8 é‡åŒ–
    â”‚
    â”œâ”€ å†…å­˜ä¼ è¾“æ…¢ â†’ å‡å°‘ H2D/D2H æ¬¡æ•°
    â”‚              â†’ ä½¿ç”¨ pinned memory
    â”‚              â†’ å¼‚æ­¥ä¼ è¾“
    â”‚
    â”œâ”€ å¤šä¸ªç®—å­æ…¢ â†’ æ£€æŸ¥èƒ½å¦èåˆ
    â”‚              â†’ ä½¿ç”¨ Constant Folding
    â”‚              â†’ å›¾ä¼˜åŒ–ï¼ˆç§»é™¤å†—ä½™èŠ‚ç‚¹ï¼‰
    â”‚
    â””â”€ åŠŸè€—é«˜ â†’ INT8 æˆ– FP16 é‡åŒ–
              â†’ é™ä½ batch size
              â†’ ä½¿ç”¨ç¨€ç–æ€§
```

---

## ğŸ“š å…³é”®èµ„æº

| èµ„æº | ç”¨é€” |
|------|------|
| `nsys profile` | GPU æ—¶é—´è½´åˆ†æ |
| `ncu` | å¾®æ¶æ„çº§ç»†èŠ‚ |
| TensorRT Profiler | é€å±‚æ—¶é—´ |
| NVIDIA Docs | æœ€ä½³å®è·µ |

---

## âœ… æ£€æŸ¥æ¸…å•

- [ ] è¿è¡Œ TensorRT profilerï¼Œæ‰¾å‡º Top 5 è€—æ—¶å±‚
- [ ] æ£€æŸ¥ profiler è¾“å‡ºä¸­"Top 5"éƒ¨åˆ†
- [ ] ç»Ÿè®¡å·ç§¯å±‚æ—¶é—´å æ¯”ï¼ˆé€šå¸¸ > 80%ï¼‰
- [ ] è¯„ä¼° FP16 æˆ– INT8 æ”¶ç›Š
- [ ] è€ƒè™‘æ˜¯å¦éœ€è¦è‡ªå®šä¹‰ Kernel
- [ ] éªŒè¯ä¼˜åŒ–åçš„æ€§èƒ½æå‡

